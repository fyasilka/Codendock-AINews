{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2123769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#чтобы полный текст посмотреть\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#from pymorphy2 import MorphAnalyzer\n",
    "# лемматизация и мешок слов\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#удаляю русские стоп слова (расширить???)\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "#import spacy\n",
    "#from spacy.lang.ru import Russian\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544fabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.DataFrame(pd.read_excel('../datasets/ai_bot_app_post.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0649ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88182 entries, 0 to 88181\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      88182 non-null  int64 \n",
      " 1   telegram_id  88182 non-null  int64 \n",
      " 2   text         88178 non-null  object\n",
      " 3   title        88177 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "main_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecff92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76435 entries, 0 to 88180\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      76435 non-null  object\n",
      " 1   telegram_id  76435 non-null  object\n",
      " 2   text         76435 non-null  object\n",
      " 3   title        76435 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "main_data = main_data.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['text', 'title'], keep='first')\n",
    "main_data.info()\n",
    "#ушло 11747 13%, пустые тоже вылетают "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea14538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ch_nan = main_data['text'].isnull().values.any()\n",
    "#print(ch_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0819a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>telegram_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>8677</td>\n",
       "      <td>18547</td>\n",
       "      <td>по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено.\\n\\nна данный момент известно о трех пострадавших. у них ожоги рук и лица.</td>\n",
       "      <td>по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id telegram_id  \\\n",
       "8555    8677       18547   \n",
       "\n",
       "                                                                                                                                                                 text  \\\n",
       "8555  по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено.\\n\\nна данный момент известно о трех пострадавших. у них ожоги рук и лица.   \n",
       "\n",
       "                                                                                     title  \n",
       "8555  по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#случайным образом выбираем 10 % новостей\n",
    "main_data = main_data.sample(frac=0.1)\n",
    "main_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0abda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7644 entries, 8555 to 25312\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      7644 non-null   object\n",
      " 1   telegram_id  7644 non-null   object\n",
      " 2   text         7644 non-null   object\n",
      " 3   title        7644 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 298.6+ KB\n"
     ]
    }
   ],
   "source": [
    "main_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a277d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_data = main_data.iloc[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5b46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b22c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['text_clean'] = main_data['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "#df_new['text_clean'] = df_new['text_clean'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "#df_new['text_clean'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23457e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['text_clean'] = main_data['text_clean'].str.replace('предложить новость', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('подписаться', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('SUBSCRIBE', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('НАСТОЯЩИЙ МАТЕРИАЛ (ИНФОРМАЦИЯ) ПРОИЗВЕДЕН, РАСПРОСТРАНЕН И (ИЛИ) НАПРАВЛЕН ИНОСТРАННЫМ АГЕНТОМ', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('ЛИБО КАСАЕТСЯ ДЕЯТЕЛЬНОСТИ ИНОСТРАННОГО АГЕНТА', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('\\n', '')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('\\t', ' ')\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace(' {2,}', ' ', regex=True)\n",
    "main_data['text_clean'] = main_data['text_clean'].str.strip()\n",
    "#df_new.head(3)   нужно ли это внизу?????\n",
    "main_data['text_clean'] = main_data['text_clean'].str.replace('\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "587b094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['text_clean'] = main_data['text_clean'].replace(r'[^\\w\\s]',' ',regex=True).replace(r'\\s+',' ',regex=True).str.lower()\n",
    "#df_new['text_clean'] = df_new['text'].replace(r'[^\\w\\s]',' ',regex=True).replace(r'\\s+',' ',regex=True).str.lower()\n",
    "#df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b33c700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>telegram_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>8677</td>\n",
       "      <td>18547</td>\n",
       "      <td>по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено.\\n\\nна данный момент известно о трех пострадавших. у них ожоги рук и лица.</td>\n",
       "      <td>по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено</td>\n",
       "      <td>по данным базы следов теракта на месте пожара на новочеркасской грэс не обнаружено на данный момент известно о трех пострадавших у них ожоги рук и лица</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id telegram_id  \\\n",
       "8555    8677       18547   \n",
       "\n",
       "                                                                                                                                                                 text  \\\n",
       "8555  по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено.\\n\\nна данный момент известно о трех пострадавших. у них ожоги рук и лица.   \n",
       "\n",
       "                                                                                     title  \\\n",
       "8555  по данным «базы» следов теракта на месте пожара на новочеркасской грэс не обнаружено   \n",
       "\n",
       "                                                                                                                                                    text_clean  \n",
       "8555  по данным базы следов теракта на месте пожара на новочеркасской грэс не обнаружено на данный момент известно о трех пострадавших у них ожоги рук и лица   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7998e91e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'WordNetLemmatize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     review \u001b[38;5;241m=\u001b[39m [nltk\u001b[38;5;241m.\u001b[39mWordNetLemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m review\n\u001b[1;32m----> 9\u001b[0m main_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_stop_words\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m     review \u001b[38;5;241m=\u001b[39m [nltk\u001b[38;5;241m.\u001b[39mWordNetLemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m review\n\u001b[1;32m----> 9\u001b[0m main_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m main_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mremove_stop_words\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36mremove_stop_words\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#tokens = re.split('\\W+', text)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m review \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m russian_stopwords]\n\u001b[1;32m----> 6\u001b[0m review \u001b[38;5;241m=\u001b[39m [nltk\u001b[38;5;241m.\u001b[39mWordNetLemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m review\n",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#tokens = re.split('\\W+', text)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m review \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m russian_stopwords]\n\u001b[1;32m----> 6\u001b[0m review \u001b[38;5;241m=\u001b[39m [\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWordNetLemmatize\u001b[49m(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m review\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'WordNetLemmatize'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_stop_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #tokens = re.split('\\W+', text)\n",
    "    review = [word for word in tokens if word not in russian_stopwords]\n",
    "    review = [nltk.WordNetLemmatize(word) for word in review]\n",
    "    return review\n",
    "\n",
    "main_data['text_clean'] = main_data['text_clean'].apply(lambda x: remove_stop_words(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd724a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b239bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('ru_core_news_md')\n",
    "def tokenize_n_normalize(sent, pat=r\"(?u)\\b\\w\\w+\\b\", morph=MorphAnalyzer()):\n",
    "    return [morph.parse(tok)[0].normal_form \n",
    "            for tok in regexp_tokenize(sent, pat)]\n",
    "\n",
    "main_data['text_lemma'] = main_data['text_clean'].map(lambda x: \" \".join(tokenize_n_normalize(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cb7e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>telegram_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>22078</td>\n",
       "      <td>128182</td>\n",
       "      <td>путин: россия будет форсировать массовый выпуск бпла, хорошо зарекомендовавших себя в боевых условиях.</td>\n",
       "      <td>путин: россия будет форсировать массовый выпуск бпла, хорошо зарекомендовавших себя в боевых условиях.</td>\n",
       "      <td>[путин, россия, форсировать, массовый, выпуск, бпла, зарекомендовавших, боевых, условиях, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id telegram_id  \\\n",
       "21944   22078      128182   \n",
       "\n",
       "                                                                                                         text  \\\n",
       "21944  путин: россия будет форсировать массовый выпуск бпла, хорошо зарекомендовавших себя в боевых условиях.   \n",
       "\n",
       "                                                                                                        title  \\\n",
       "21944  путин: россия будет форсировать массовый выпуск бпла, хорошо зарекомендовавших себя в боевых условиях.   \n",
       "\n",
       "                                                                                        text_clean  \n",
       "21944  [путин, россия, форсировать, массовый, выпуск, бпла, зарекомендовавших, боевых, условиях, ]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1943fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data.to_csv('../datasets/ready_to_work_try1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ef21c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data.to_excel(\"../datasets/ready_to_work.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
