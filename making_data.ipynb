{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14251bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5470ee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (588489674.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://www.kommersant.ru/RSS/section-sport.xml\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'Kommersant': 'https://www.kommersant.ru/RSS/corp.xml',\n",
    "https://www.kommersant.ru/RSS/section-sport.xml\n",
    "    https://www.kommersant.ru/RSS/news.xml\n",
    "        https://www.kommersant.ru/RSS/corp.xml #материалы сайта коммерсант\n",
    "            https://www.kommersant.ru/RSS/section-economics.xml\n",
    "                https://www.kommersant.ru/RSS/section-culture.xml\n",
    "                    https://www.kommersant.ru/RSS/section-style.xml\n",
    "                        https://www.kommersant.ru/RSS/Autopilot_on.xml\n",
    "                            https://www.kommersant.ru/RSS/section-hitech.xml\n",
    "                                https://www.kommersant.ru/RSS/section-business.xml\n",
    "                                    https://www.kommersant.ru/RSS/section-society.xml\n",
    "                                        <link href=\"https://lenta.ru/rss/google-newsstand/main/\" rel=\"alternate\" type=\"application/rss+xml\">\n",
    "                                        <href=\"https://ria.ru/export/rss2/archive/index.xml\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9415faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_feeds = {'ria': 'https://ria.ru/export/rss2/archive/index.xml'} #пример словаря RSS-лент \n",
    "                                                                  #русскоязычных источников\n",
    "\n",
    "f_all_news = '../datasets/show.csv' \n",
    "f_certain_news = '../datasets/show1.csv' #пример пути файла\n",
    "\n",
    "vector1 = 'ДолЛАР|РубЛ|ЕвРО' #пример таргетов\n",
    "vector2 = 'ЦБ|СбЕРбАНК|курс'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c316151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url(url_feed): #функция получает линк на рсс ленту, возвращает        \n",
    "# распаршенную ленту с помощью feedpaeser\n",
    "    return feedparser.parse(url_feed)  \n",
    "    \n",
    "def getHeadlines(url_feed): #функция для получения заголовков новости\n",
    "    headlines = []\n",
    "    lenta = check_url (url_feed)\n",
    "    for item_of_news in lenta['items']:\n",
    "        headlines.append(item_of_news ['title'])\n",
    "    return headlines\n",
    "\n",
    "#def getDescriptions(url_feed): #функция для получения описания новости\n",
    "#    descriptions = []\n",
    " #   lenta = check_url(url_feed)\n",
    "  #  for item_of_news in lenta['items']:\n",
    "   #     descriptions.append(item_of_news ['description'])\n",
    "    #return descriptions\n",
    "\n",
    "def getLinks(url_feed): #функция для получения ссылки на источник новости\n",
    "    links = []\n",
    "    lenta = check_url(url_feed)\n",
    "    for item_of_news in lenta['items']:\n",
    "        links.append(item_of_news ['link'])\n",
    "    return links\n",
    "\n",
    "def getDates(url_feed): #функция для получения даты публикации новости\n",
    "    dates = []\n",
    "    lenta = check_url(url_feed)\n",
    "    for item_of_news in lenta['items']:\n",
    "        dates.append(item_of_news ['published'])\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6feefec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allheadlines = []\n",
    "alldescriptions = []\n",
    "alllinks = []\n",
    "alldates = []\n",
    "# Прогоняем наши URL и добавляем их в наши пустые списки\n",
    "for key,url in our_feeds.items():\n",
    "    allheadlines.extend( getHeadlines(url) )\n",
    "    \n",
    "#for key,url in our_feeds.items():\n",
    "#    alldescriptions.extend( getDescriptions(url) )\n",
    "    \n",
    "for key,url in our_feeds.items():\n",
    "    alllinks.extend( getLinks(url) )\n",
    "    \n",
    "for key,url in our_feeds.items():\n",
    "    alldates.extend( getDates(url) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36bf5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_news(all_news_filepath): #функция для записи всех новостей в .csv, \n",
    "# возвращает нам этот датасет\n",
    "    header = ['Title','Description','Links','Publication Date'] \n",
    "\n",
    "    with open(all_news_filepath, 'w', encoding='utf-8-sig') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        writer.writerow(i for i in header) \n",
    "\n",
    "        for a,b,c,d  in zip(allheadlines,alldescriptions,\n",
    "                            alllinks, alldates):\n",
    "            writer.writerow((a,b,c,d))\n",
    "\n",
    "\n",
    "        df = pd.read_csv(all_news_filepath)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "155e2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looking_for_certain_news(all_news_filepath, certain_news_filepath, target1, target2): #функция для поиска, а затем записи\n",
    "                #определенных новостей по таргета,\n",
    "                #затем возвращает этот датасет\n",
    "    df = pd.read_csv(all_news_filepath)\n",
    "    \n",
    "    result = df.apply(lambda x: x.str.contains(target1, na=False,\n",
    "                                    flags = re.IGNORECASE, regex=True)).any(axis=1)\n",
    "    result2 = df.apply(lambda x: x.str.contains(target2, na=False,\n",
    "                                    flags = re.IGNORECASE, regex=True)).any(axis=1)\n",
    "    new_df = df[result&result2]\n",
    "        \n",
    "    new_df.to_csv(certain_news_filepath\n",
    "                     ,sep = '\\t', encoding='utf-8-sig')\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98be6ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwrite_all_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_all_news\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#все новости\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 15\u001b[0m, in \u001b[0;36mwrite_all_news\u001b[1;34m(all_news_filepath)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a,b,c,d  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(allheadlines,alldescriptions,\n\u001b[0;32m     11\u001b[0m                         alllinks, alldates):\n\u001b[0;32m     12\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow((a,b,c,d))\n\u001b[1;32m---> 15\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_news_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:555\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "write_all_news(f_all_news) \n",
    "#все новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f9ef6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Publication Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Работники держат курс на повышение // Готов ли российский бизнес платить сотрудникам за границей в валюте</td>\n",
       "      <td>Сотрудники российских компаний, живущие за рубежом, просят привязать зарплаты к курсу валюты. Больше половины работодателей в августе получили просьбы и об индексации вознаграждения со стороны таких специалистов, показал опрос HeadHunter. Поводом стало резкое ослабление рубля. Как отмечается, 23% предприятий планируют пойти навстречу и повысить оклад удаленщикам, проживающим за границей. Столько же привяжут выплаты в рублях к курсу доллара или евро. Еще 23% не примут никаких мер.</td>\n",
       "      <td>https://www.kommersant.ru/doc/6212688</td>\n",
       "      <td>Thu, 14 Sep 2023 19:16:03 +0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        Title  \\\n",
       "24  Работники держат курс на повышение // Готов ли российский бизнес платить сотрудникам за границей в валюте   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Description  \\\n",
       "24  Сотрудники российских компаний, живущие за рубежом, просят привязать зарплаты к курсу валюты. Больше половины работодателей в августе получили просьбы и об индексации вознаграждения со стороны таких специалистов, показал опрос HeadHunter. Поводом стало резкое ослабление рубля. Как отмечается, 23% предприятий планируют пойти навстречу и повысить оклад удаленщикам, проживающим за границей. Столько же привяжут выплаты в рублях к курсу доллара или евро. Еще 23% не примут никаких мер.   \n",
       "\n",
       "                                    Links                 Publication Date  \n",
       "24  https://www.kommersant.ru/doc/6212688  Thu, 14 Sep 2023 19:16:03 +0300  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "looking_for_certain_news(f_all_news, f_certain_news, vector1, vector2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_news = f_all_news.conncat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa42e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca3349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
